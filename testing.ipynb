{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path, PureWindowsPath\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from PIL import Image as im\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"data/results/baseline/\"\n",
    "data_path_test = \"data/Testing_set2/\"\n",
    "# extract information from train.txt\n",
    "f = open(os.path.join(data_path_test, \"testing_set.txt\"), \"r\")\n",
    "contents_test = f.readlines()\n",
    "test_image, test_kp, gt_test_image = [], [], []\n",
    "for sample in contents_test:\n",
    "    sample = sample.split()\n",
    "    ii, kk, gi = sample[0], sample[1], sample[2]\n",
    "    # print(data_path_test+ii)\n",
    "    # print(data_path_test+kk)\n",
    "\n",
    "    truth = gi.split('/')[1]\n",
    "\n",
    "    test_image.append(data_path_test+ii)\n",
    "    test_kp.append(data_path_test+kk)\n",
    "    gt_test_image.append(truth)\n",
    "\n",
    "    tmp_im = cv2.imread(data_path_test+ii, 0)\n",
    "\n",
    "    er_kp = np.loadtxt(data_path_test+kk)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_images = []\n",
    "images = []\n",
    "for i in range(len(test_kp)):\n",
    "    gt_im = test(test_kp[i])\n",
    "\n",
    "    images.append(cv2.imread(test_image[i]))\n",
    "    kp_images.append(gt_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the input data\n",
    "# concatenate source with keypoint\n",
    "concat_data = []\n",
    "concat_data2 = []\n",
    "image_test_list = []\n",
    "kp_image_list = []\n",
    "\n",
    "for i in range(len(images)):\n",
    "\n",
    "    a = np.asarray(im.fromarray(kp_images[i]*255))\n",
    "    col_a = cv2.cvtColor(a, cv2.COLOR_GRAY2RGB) # take the rgb of the key points\n",
    "\n",
    "    \n",
    "    kp_image_list.append( cv2.resize(col_a, [64,64]) /255 )\n",
    "    image_test_list.append( cv2.resize(images[i], [64,64]) /255 )\n",
    "\n",
    "\n",
    "    im_v = kp_image_list[i] + image_test_list[i] # cv2.hconcat( [images[i], kp_images[i]+images[i]] )# .reshape(64,64,3)\n",
    "\n",
    "    # resize image\n",
    "    im_v = im_v\n",
    "    concat_data.append(im_v) # .reshape([1,64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-cf3333196b6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_test_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "for i in range(len(concat_data)):\n",
    "    result = model(image_test_list[i])\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "37ea763e17ca16afe8a1ef43c39f4d44b0f93bee18d7df77b006282f7f085010"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}